---
title: Data Processing
jupyter: python3
---

### Graphs:
- 1. Cum. Mass vs time [groupby year] [per person (divide by num students)]
- 2. 
- 3. 
- 4. 

### subtasks:
- Integrate previous name consolidations


## Imports

```{python}
#| vscode: {languageId: python}
import pandas as pd
from pandas.api.types import is_numeric_dtype
import matplotlib.pyplot as plt
import numpy as np
import calendar
```

## Load data file into pandas dataframe

### Download Data from current Google Sheet

```{python}
#| vscode: {languageId: python}
import os
import requests
import sys

# sheet view/edit link: https://docs.google.com/spreadsheets/d/1ROWww6f3hB2OObk5Kax_cfIP3lo987lxhInNmToUtCI/edit?resourcekey#gid=549923050
# NEWEST 3d print data https://docs.google.com/spreadsheets/d/1UYjxRt_q7meIHVxc4GUn3_DoRElXlRMey5oqHZZmJsI/edit?usp=sharing
sheet_id = "1ROWww6f3hB2OObk5Kax_cfIP3lo987lxhInNmToUtCI"
old_id = "16gWwdpJz6Tpa92GiV3Jq7wrkmSj5Y4rFsRes-XTiOFQ"
newest_id = "1UYjxRt_q7meIHVxc4GUn3_DoRElXlRMey5oqHZZmJsI"
def getGoogleSeet(spreadsheet_id, outDir, outFile):
  
  url = f'https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=csv'
  response = requests.get(url)
  if response.status_code == 200:
    filepath = os.path.join(outDir, outFile)
    with open(filepath, 'wb') as f:
      f.write(response.content)
      print('CSV file saved to: {}'.format(filepath))    
  else:
    print(f'Error downloading Google Sheet: {response.status_code}')
    sys.exit(1)


##############################################

outDir = './'

os.makedirs(outDir, exist_ok = True)
filepath = getGoogleSeet(sheet_id, outDir, "data/data_current.csv")
old_filepath = getGoogleSeet(old_id, outDir, "data/data_old_python.csv")
newest_filepath = getGoogleSeet(newest_id, outDir, "data/data_newest.csv")
```

### Read Data into Pandas Dataframes, clean, concat

```{python}
#| vscode: {languageId: python}
### DATA CLEANING HELPER FUNCTIONS
def fix_timestamps(df:pd.DataFrame):
    """
    Convert timestamp column into pandas datetime series

    Args:
        df (pd.DataFrame): dataframe
    """
    # convert timestamp column from str to pd.Timestamp
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # drop rows with undefined timestamps
    df = df[df["timestamp"].notna()]
    
    return df

# TODO: Fix this regex. High averages in the mass come from removing periods and considering decimal masses as ints
def fix_print_mass(df:pd.DataFrame):
    """
    Clean and convert, and rename "print mass (grams)" column

    Args:
        df (pd.DataFrame): dataframe
    """
    # clean all alphabetic characters from print_mass col and replace empty strings with nan
    # TODO: Fix this regex. High averages in the mass come from removing periods and considering decimal masses as ints
    
    if not is_numeric_dtype(df['mass']):
        # df["mass"] = df["mass"].str.replace(r'[^\d\.]', '', regex=True).replace(r'/(\.\d+)+/', '', regex=True).replace('.','').replace('...','').replace('', np.nan)
        df["mass"] = df["mass"].str.replace(r'\D', '', regex=True).replace('', np.nan)
        # df["mass"] = df["mass"].str.replace(r'[^\d.]', '', regex=True).replace(r'[.][0-9]+$', "", regex=True).replace(r".","", regex=True).replace('', np.nan)

    df = df[df["mass"].notnull()] # remove any colums with nan print mass
    df["mass"] = df["mass"].astype(float)

    # filter out rediculous masses (10kg)
    df = df[df["mass"] < 10000]
    return df

def process_csv_file(path:str, rename_map:dict):
    """
    Load data from csv file, store into pd dataframe, downselect and rename columns, clean data.
    Provide `rename_map` dictionary to specify which columns to downselect to and their new names.

    Args:
        path (str): path to csv file
        rename_map (dict {"new col name":"old col name"}): dictates which columns to put into returned dataframe

    Returns:
        pd.DataFrame: cleaned and downselected dataframe generated from csv file
    """
    # read current data from csv
    df = pd.read_csv(path)

    # downselect and rename relevant columns from dataframe according to rename_map dict
    df = df[list(rename_map.values())]                # downselect
    df.rename(columns = rename_map, inplace = True) # rename
    df.columns = rename_map.keys()

    # cleaning timestamps
    df = fix_timestamps(df)
    df = fix_timestamps(df)

    # clean print mass in grams column
    df = fix_print_mass(df)

    return df
    
# process "very old" data
very_old_rename_map = {
    "timestamp" : "timestamp",
    "name"      : "name",
    "mass"      : "print_mass_grams",
    "reason"    : "reason_print",
    "class"     : "class"
}
df_veryold = process_csv_file("data/3d_very_old.csv", very_old_rename_map)
df_veryold.head()

# process "old" data
old_rename_map = {
    "timestamp" : "Timestamp",
    "name"      : "Your Name",
    "mass"      : "Print Mass (in grams)",
    # "reason" : "What are you printing for?",
    # "class"  : "If you chose Class Project, which class? If a Project Team/Club, which group?"
}
df_old = process_csv_file("data/data_old_python.csv", old_rename_map)

# Process "current" data
curr_rename_map = {
    "timestamp": "Timestamp",
    "name"   : "Name",
    "mass"   : "Print Mass (in grams)",
    "reason" : "What are you printing for?",
    "class"  : "If you chose Class Project, which class? If a Project Team/Club, which group?"
}
df_curr = process_csv_file("data/data_current.csv", curr_rename_map)

# Process "very new" data
newest_rename_map = {
    "timestamp": "Start time",
    "name"   : "Your Name",
    "mass"   : "Print Mass (Grams)",
    "reason" : "Reason For Print",
    "class"  : "If applicable, which class, research group, or project team?"
}
df_newest = process_csv_file("data/data_current.csv", curr_rename_map)
df_newest.head()


# concat all data
df = pd.concat([df_veryold, df_old, df_curr, df_newest])

# sort data by timestamp
df.sort_values(by="timestamp", inplace=True)
df.to_csv(path_or_buf="data/rajiv_output.csv")

print(df.head())
```

## print mass vs time

### Cumulative Mass

```{python}
#| vscode: {languageId: python}
# create new dataframe with copies of timestamp and print_mass_grams columns
df_print_mass = df[["timestamp", "mass"]]

# add column for cumulative sum of print masses
df_print_mass["print_mass_cum"] = df_print_mass["mass"].cumsum()

# Create a line plot using Matplotlib
plt.figure(figsize=(10, 6))  # Optional: Set the figure size
plt.plot(df_print_mass['timestamp'], df_print_mass["print_mass_cum"].div(1000), linestyle='-', color='b', label='print_mass_grams vs. Time')
plt.title("Print mass vs. Time")
plt.xlabel('Time')
plt.ylabel("Cumulative print mass (kg)")
plt.legend()
plt.grid(True)

# Display the plot
plt.show()
```

### Groupby Year

```{python}
#| vscode: {languageId: python}
# function to groupby academic year
def get_academic_year(timestamp:pd.Timestamp):
    """
    Return the academic year string of a timestamp

    Args:
        timestamp (pd.Timestamp): timestamp object

    Returns:
        str: Academic year string, e.g. "21/22"
    """
    year = int(repr(timestamp.year)[-2:]) # last two digits of year
    if timestamp.month < 9: # before september: year-1/year
        return f"{year-1}/{year}"
    else:                   # after september: year/year+1
        return f"{year}/{year+1}"

def get_semester(timestamp:pd.Timestamp):
    """
    Return the semester string of a timestamp

    Args:
        timestamp (pd.Timestamp): timestamp object

    Returns:
        str: Semester string, e.g. "SP21"
    """
    year = int(repr(timestamp.year)[-2:]) # lat two digits of year
    if 1 <= timestamp.month <= 5: # before september spring semester
        return f"SP{year}"
    elif 9 <= timestamp.month <= 12:                   # after september: fall semester
        return f"FA{year}"

def get_population_on_campus(semester:str, population_dict=None):
    """
    Return the "population" for each entry, population on campus at that time
    
    Args:
        df (pandas dataframe): relevant rows are semester (str) and mass (float)
            semester (str): string of 2 alpha character semester (FA or SP) followed by 2 numeric character year (i.e. 19 or 20)
            mass (float): float of mass in grams
        population_dict (optional): dict with semester as keys and number of people as values. Can be used to override manually 
            inputted person mapping with number of individuals printing per semester
            TODO: add number of people printing per semester calculation after scatter plotting is completed
    Returns:
        normalized_mass (float)): mass of print divided by number of people currently on campus
    """
    # if you don't have an inputted mapping for students per semester, use the default
    if not population_dict:
        population_dict = {"FA18":340, "SP19":326, "FA19":347, "SP20":333, "FA20":113, "SP21":113, "FA21":360, "FA22":347}
    if semester in population_dict: # before september spring semester
        return population_dict[semester]
    else:                   # after september: fall semester
        # print(f"{semester} not in population dict!")
        return np.nan
# add academic year column to df
df["academic year"] = df["timestamp"].apply(lambda x: get_academic_year(x))
df["semester"] = df["timestamp"].apply(lambda x: get_semester(x))
df["population on campus"] = df["semester"].apply(lambda x: get_population_on_campus(x))
df["normalized mass"] = df["mass"].divide(df["population on campus"])
df["normalized mass"].describe()
```

```{python}
#| vscode: {languageId: python}
def get_ac_year_day(timestamp: pd.Timestamp):
    """
    Get day of the academic year

    Args:
        timestamp (pd.Timestamp): timestamp to convert
    """
    if timestamp.month >=9:
       return timestamp.day_of_year - 244
    else:
        return timestamp.day_of_year + 365 - 244

# Set up plot
plt.figure(figsize=(10, 6))  # Optional: Set the figure size
# fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)

plt.xlabel('date')
plt.grid(True)



# group data by academic semester
sem_groupby = df.groupby('semester')[["timestamp", "mass", "normalized mass"]]

p_year = 14
color = "blue"

# plot for each academic year on same axes
for sem, _df in sem_groupby:
    # if sem in ["14/15", "15/16", "16/17", "17/18", "23/24", "22/23"]:    #"17/18",, "19/20", "18/19", "20/21"]
    #     pass
    # else:
    #     # plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["mass"].cumsum(), label=f'{ac_year}')
    #     plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["mass"].cumsum(), label=f'{sem[:2]}')
    year = sem[-2:]

    # # cycle color
    # if year != p_year:
    #     color = next(ax1._get_lines.prop_cycler)['color']

    # p_year = year

    if year in ["14"]:    #"17/18",, "19/20", "18/19", "20/21"]
        pass
    else:
        plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["normalized mass"].cumsum(), label=f'{sem}')

# Set y-axis label for left subplot only
plt.title('Cumulative print mass (g)')
# plt.set_title("Fall")
# plt.set_title("Spring")
# plt.title("Cumulative Print mass vs. date by academic year and semester")
# Add title to subplot
# plt.suptitle(' Cumulative Print mass vs. date by academic year and semester ', fontsize=20)

# Display the plot
plt.legend(title="Academic Year")
# plt.legend(title="Academic Year")
plt.show()

df.head()
```

### Class/Reason Data Bar Charts

```{python}
#| vscode: {languageId: python}
# Set up plot
plt.figure(figsize=(10, 6))  # Optional: Set the figure size
plt.title("Filament Used Per Semester")         # Per reason
plt.xlabel('date')
plt.ylabel("Cumulative print mass (g)")
plt.grid(True)



# group data by academic year
sem_groupby = df.groupby('academic year')[["timestamp", "mass"]]

# plot for each academic year on same axes
for sem, _df in sem_groupby:
    if sem in ["14/15", "15/16", "16/17", "17/18", "23/24"]:    #"17/18",, "19/20", "18/19", "20/21", "22/23"
        pass
    else:
        print(f"year is {sem}")
        plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["mass"].cumsum(), label=f'{sem}')
    # print(_df.head())

# Display the plot
plt.legend(title="Academic Year")
plt.show()
```

### Individual Person Consumption Scatterplot

```{python}
#| vscode: {languageId: python}
def person_point_scatter(df:pd.DataFrame, semester_list):
    """
    Create a scatterplot with y axis total mass and x axis number of prints and 
    one point for each name represented in the dataset

    Args:
        dataframe (pd.DataFrame): dataframe with rows name, mass, semester, and academic year
        semester_list (list): list of strings, in form: [FA19, SP20] to graph only 
            the per person data in the 19-20 school year.
    """
    # group data by academic year
    sem_groupby = df.groupby('semester')[["timestamp", "name", "mass"]]
    
    # create new dataframe for sums
    person_prints_overtime = pd.DataFrame(columns=["name", "total mass", "total prints"])
    # plot for each academic year on same axes
    for sem, _df in sem_groupby:
        if sem not in semester_list:
            print(f"ignoring year {sem}")    
            pass
        else:
            print(f"semester is {sem}")
            
            # iterate through entries in dataframe and check if name has been recorded
            for idx, row in df.iterrows():
                entry = df.iloc[idx]
                # if it doesn't, create and populate row in person_prints_overtime
                if entry["name"] not in person_prints_overtime["name"].values:
                    first_entry = pd.Series({"name":entry["name"],"total mass":entry["mass"], "total prints":1})
                    person_prints_overtime.loc[person_prints_overtime.shape[0]] = first_entry
                # if it does, add this entry's print mass to the values and +1 num prints to the right name in sum df
                else:
                    person_prints_overtime.loc[person_prints_overtime["name"]==entry["name"], "total mass"] +=entry["mass"]
                    person_prints_overtime.loc[person_prints_overtime["name"]==entry["name"], "total prints"] += 1
    # plot every entry in the dataframe on the scatterplot 
    ax1 = person_prints_overtime.plot.scatter(x="total prints", y="total mass")
        # plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["mass"].cumsum(), label=f'{sem}')
        # print(_df.head())

    # Set up plot
    semester_ends = [semester_list if len(semester_list)==1 else semester_list[0]+semester_list[-1]]
    ax1.set_title(f"Individual Consumption Specifics {', '.join(semester_ends)}")         # Per reason
    ax1.set_xlabel('Total prints')
    ax1.set_ylabel("Total Print Mass (g)")

    # Display the plot
    ax1.legend(title="Individual People")
    person_prints_overtime.sort_values(by="total mass", inplace=True)

    return person_prints_overtime

semesters_to_scatter = ["FA18", "SP19", "FA19", "SP20", "FA20", "SP21", "FA21", "FA22"]
output_scatter = person_point_scatter(df, semesters_to_scatter)
```

## Deal with correcting shitty data (uuuhhhHHH)

```{python}
#| vscode: {languageId: python}
def correct_series(series, map:dict):
    """
    Iterate through each correct value in the map dictionary,
    performing a regex string replacement on the series that
    overwrites any matching value with the coorect value given
    by the map

    Args:
        series (pandas series): series to be corrected
        map (dict): dictionary that maps correction keys to 
                    a regex expression targeting incorrect
                    values (<correct value> : <regex query for misnomers>)
    
    Return:
        (pandas series): corrected pandas series
    """
    for correction_key in map:
        series = series.str.replace(map[correction_key], correction_key, regex=True, case=False)
    
    return series

# dictionary for defining name correction map
class_names_correction_map = {
    "DesNat" : "Desnat|desnT|DesNat|dednat|Des Nat|ddesnat|desnat|desNat|Design Nature",
    "Pass. Pursuit" : "passion.*",
    "PIE" : "pie.*",
    "DFM" : "dfm|.*manufact.*",
    "Scope" : ".*scope.*",
    "IS" : ".*indep.*|is.*",
    "Ren. Energy" : ".*renewable.*",
    "EEC" : ".*eec.*",
    "Mech Proto" : ".*proto.*|Mech Proto",
    "QEA" : ".*qea.*",
    "Research" : ".*research.*|.*lair.*",
    "P&M" : ".*market.*|p&.*|p[[:space:]]&.*|p &m",
    "SustDes" : ".*sust.*",
    "RoboSys" : ".*robos.*|.*Robotic System*.",
    "DBF" : ".*dbf.*|design[[:space:]]bu.*",
    "Formula" : "formula",
    "Large 3D Printer" : ".*rint*.",
    "Project Team or Club" : "DBF|Formula|Rocketry|Baja|pint"
}


# correct class names
df["class names corrected"] = correct_series(df["class"], class_names_correction_map)
```

### Create Bar Graph Plot

```{python}
# find top 5 most frequent classes
n = 10 # number of class categories to plot
top_classes = df['class names corrected'].value_counts()[:n].index.tolist()

# # for testing purposes (before we dedupe the class names) I will test with this list of the top 5 class names
# classes_top5 = ['Mech Proto', 'POE', 'DesNat', 'PIE', 'Project Team or Club']

# downselect df to top 5 classes only
df_top_classes = df[df["class names corrected"].isin(top_classes)]
df_top_classes.head()

# group by class name and semester
double_groupby = df_top_classes.groupby(["class names corrected", "semester"])["mass"].sum()

df_double_groupby = pd.DataFrame(double_groupby)
print(df_double_groupby)
```

### Testing out how to make the bar graph

#### Per class bar plot

```{python}
# convert that double groupby object into an iterable nested dict structure
semester_totals_by_class = {}
for key in double_groupby.keys():
    if key[0] not in semester_totals_by_class:
        semester_totals_by_class[key[0]] = {key[1]: double_groupby[key]}
    else:
        semester_totals_by_class[key[0]].update({key[1]: double_groupby[key]})

# test
for class_name, mass_by_sem in semester_totals_by_class.items():
    print(f"-------------{class_name}-------------")
    for sem, total_mass in mass_by_sem.items():
        print(f"{sem}: {total_mass}g")

# creating the dataset
data = semester_totals_by_class["DesNat"]

semesters = list(data.keys())
print(semesters)
total_masses = list(data.values())
print(total_masses)

fig = plt.figure(figsize = (10, 5))

# creating the bar plot
plt.bar(semesters, total_masses,
		width = 0.4)

plt.xlabel("Semester")
plt.ylabel("Total mass printed")
plt.title("DesNat")
plt.show()
```

#### All Classes Bar Plot

```{python}
ax = pd.crosstab(df_top_classes["class names corrected"], df_top_classes["semester"]).plot.bar()

ax.set_title("Filiment Consumption by Class")
ax.set_ylabel("Filiment Consumed (g)")
ax.set_xlabel("")
ax.tick_params(labelrotation = 90)

plt.show()

print(df_top_classes)
```

## Deal with student names?

```{python}
#| vscode: {languageId: python}
# do later, holy shit
```

