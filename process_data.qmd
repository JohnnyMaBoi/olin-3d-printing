---
title: Data Processing
jupyter: python3
---


### Graphs:
- 1. Cum. Mass vs time [groupby year] [per person (divide by num students)]
- 2. 
- 3. 
- 4. 

### subtasks:
- Integrate previous name consolidations


## Imports

```{python}
import pandas as pd
from pandas.api.types import is_numeric_dtype
import matplotlib.pyplot as plt
import numpy as np
import calendar
```

## Load data file into pandas dataframe

### Download Data from current Google Sheet

```{python}
import os
import requests
import sys

# sheet view/edit link: https://docs.google.com/spreadsheets/d/1ROWww6f3hB2OObk5Kax_cfIP3lo987lxhInNmToUtCI/edit?resourcekey#gid=549923050
# NEWEST 3d print data https://docs.google.com/spreadsheets/d/1UYjxRt_q7meIHVxc4GUn3_DoRElXlRMey5oqHZZmJsI/edit?usp=sharing
sheet_id = "1ROWww6f3hB2OObk5Kax_cfIP3lo987lxhInNmToUtCI"
old_id = "16gWwdpJz6Tpa92GiV3Jq7wrkmSj5Y4rFsRes-XTiOFQ"
newest_id = "1UYjxRt_q7meIHVxc4GUn3_DoRElXlRMey5oqHZZmJsI"
def getGoogleSeet(spreadsheet_id, outDir, outFile):
  
  url = f'https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=csv'
  response = requests.get(url)
  if response.status_code == 200:
    filepath = os.path.join(outDir, outFile)
    with open(filepath, 'wb') as f:
      f.write(response.content)
      print('CSV file saved to: {}'.format(filepath))    
  else:
    print(f'Error downloading Google Sheet: {response.status_code}')
    sys.exit(1)


##############################################

outDir = './'

os.makedirs(outDir, exist_ok = True)
filepath = getGoogleSeet(sheet_id, outDir, "data/data_current.csv")
old_filepath = getGoogleSeet(old_id, outDir, "data/data_old_python.csv")
newest_filepath = getGoogleSeet(newest_id, outDir, "data/data_newest.csv")
```

### Read Data into Pandas Dataframes, clean, concat

```{python}
### DATA CLEANING HELPER FUNCTIONS
def fix_timestamps(df:pd.DataFrame):
    """
    Convert timestamp column into pandas datetime series

    Args:
        df (pd.DataFrame): dataframe
    """
    # convert timestamp column from str to pd.Timestamp
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # drop rows with undefined timestamps
    df = df[df["timestamp"].notna()]

    return df

# TODO: Fix this regex. High averages in the mass come from removing periods and considering decimal masses as ints
def fix_print_mass(df:pd.DataFrame):
    """
    Clean and convert, and rename "print mass (grams)" column

    Args:
        df (pd.DataFrame): dataframe
    """
    # clean all alphabetic characters from print_mass col and replace empty strings with nan
    # TODO: Fix this regex. High averages in the mass come from removing periods and considering decimal masses as ints
    
    if not is_numeric_dtype(df['mass']):
        # df["mass"] = df["mass"].str.replace(r'[^\d\.]', '', regex=True).replace(r'/(\.\d+)+/', '', regex=True).replace('.','').replace('...','').replace('', np.nan)
        df["mass"] = df["mass"].str.replace(r'\D', '', regex=True).replace('', np.nan)

    df = df[df["mass"].notnull()] # remove any colums with nan print mass
    df["mass"] = df["mass"].astype(float)

    # filter out rediculous masses (10kg)
    df = df[df["mass"] < 10000]
    return df

def process_csv_file(path:str, rename_map:dict):
    """
    Load data from csv file, store into pd dataframe, downselect and rename columns, clean data.
    Provide `rename_map` dictionary to specify which columns to downselect to and their new names.

    Args:
        path (str): path to csv file
        rename_map (dict {"new col name":"old col name"}): dictates which columns to put into returned dataframe

    Returns:
        pd.DataFrame: cleaned and downselected dataframe generated from csv file
    """
    # read current data from csv
    df = pd.read_csv(path)

    # downselect and rename relevant columns from dataframe according to rename_map dict
    df = df[list(rename_map.values())]                # downselect
    # df.rename(columns = rename_map, inplace = True) # rename
    df.columns = rename_map.keys()

    # cleaning timestamps
    df = fix_timestamps(df)

    # clean print mass in grams column
    df = fix_print_mass(df)

    return df
    
# process "very old" data
very_old_rename_map = {
    "timestamp" : "timestamp",
    "name"      : "name",
    "mass"      : "print_mass_grams",
    "reason"    : "reason_print",
    "class"     : "class"
}
df_veryold = process_csv_file("data/3d_very_old.csv", very_old_rename_map)
df_veryold.head()

# process "old" data
old_rename_map = {
    "timestamp" : "Timestamp",
    "name"      : "Your Name",
    "mass"      : "Print Mass (in grams)",
    # "reason" : "What are you printing for?",
    # "class"  : "If you chose Class Project, which class? If a Project Team/Club, which group?"
}
df_old = process_csv_file("data/data_old_python.csv", old_rename_map)

# Process "current" data
curr_rename_map = {
    "timestamp": "Timestamp",
    "name"   : "Name",
    "mass"   : "Print Mass (in grams)",
    "reason" : "What are you printing for?",
    "class"  : "If you chose Class Project, which class? If a Project Team/Club, which group?"
}
df_curr = process_csv_file("data/data_current.csv", curr_rename_map)

# Process "very new" data
newest_rename_map = {
    "timestamp": "Start time",
    "name"   : "Your Name",
    "mass"   : "Print Mass (Grams)",
    "reason" : "Reason For Print",
    "class"  : "If applicable, which class, research group, or project team?"
}
df_newest = process_csv_file("data/data_current.csv", curr_rename_map)
df_newest.head()


# concat all data
df = pd.concat([df_veryold, df_old, df_curr, df_newest])

# sort data by timestamp
df.sort_values(by="timestamp", inplace=True)
df.to_csv(path_or_buf="data/rajiv_output.csv")

print(df.dtypes)
```

## print mass vs time

### Cumulative Mass

```{python}
# create new dataframe with copies of timestamp and print_mass_grams columns
df_print_mass = df[["timestamp", "mass"]]

# add column for cumulative sum of print masses
df_print_mass["print_mass_cum"] = df_print_mass["mass"].cumsum()

# Create a line plot using Matplotlib
plt.figure(figsize=(10, 6))  # Optional: Set the figure size
plt.plot(df_print_mass['timestamp'], df_print_mass["print_mass_cum"].div(1000), linestyle='-', color='b', label='print_mass_grams vs. Time')
plt.title("Print mass vs. Time")
plt.xlabel('Time')
plt.ylabel("Cumulative print mass (kg)")
plt.legend()
plt.grid(True)

# Display the plot
plt.show()
```

### Groupby Year

```{python}
# function to groupby academic year
def get_academic_year(timestamp:pd.Timestamp):
    """
    Return the academic year string of a timestamp

    Args:
        timestamp (pd.Timestamp): timestamp object

    Returns:
        str: Academic year string, e.g. "21/22"
    """
    year = int(repr(timestamp.year)[-2:]) # last two digits of year
    if timestamp.month < 9: # before september: year-1/year
        return f"{year-1}/{year}"
    else:                   # after september: year/year+1
        return f"{year}/{year+1}"

def get_semester(timestamp:pd.Timestamp):
    """
    Return the semester string of a timestamp

    Args:
        timestamp (pd.Timestamp): timestamp object

    Returns:
        str: Semester string, e.g. "SP21"
    """
    year = int(repr(timestamp.year)[-2:]) # lat two digits of year
    if 1 <= timestamp.month <= 5: # before september spring semester
        return f"SP{year}"
    elif 9 <= timestamp.month <= 12:                   # after september: fall semester
        return f"FA{year}"

def get_population_on_campus(semester:str, population_dict=None):
    """
    Return the "population" for each entry, population on campus at that time
    
    Args:
        df (pandas dataframe): relevant rows are semester (str) and mass (float)
            semester (str): string of 2 alpha character semester (FA or SP) followed by 2 numeric character year (i.e. 19 or 20)
            mass (float): float of mass in grams
        population_dict (optional): dict with semester as keys and number of people as values. Can be used to override manually 
            inputted person mapping with number of individuals printing per semester
            TODO: add number of people printing per semester calculation after scatter plotting is completed
    Returns:
        normalized_mass (float)): mass of print divided by number of people currently on campus
    """
    # if you don't have an inputted mapping for students per semester, use the default
    if not population_dict:
        population_dict = {"FA18":340, "SP19":326, "FA19":347, "SP20":333, "FA20":113, "SP21":113, "FA21":360, "FA22":347}
    if semester in population_dict: # before september spring semester
        return population_dict[semester]
    else:                   # after september: fall semester
        # print(f"{semester} not in population dict!")
        return np.nan

# add aacademic year column to df
df["academic year"] = df["timestamp"].apply(lambda x: get_academic_year(x))
df["semester"] = df["timestamp"].apply(lambda x: get_semester(x))
df["population on campus"] = df["semester"].apply(lambda x: get_population_on_campus(x))
df["normalized mass"] = df["mass"].divide(df["population on campus"])
df["normalized mass"].describe()
```

```{python}
def get_ac_year_day(timestamp: pd.Timestamp):
    """
    Get day of the academic year

    Args:
        timestamp (pd.Timestamp): timestamp to convert
    """
    if timestamp.month >=9:
       return timestamp.day_of_year - 244
    else:
        return timestamp.day_of_year + 365 - 244

# Set up plot
plt.figure(figsize=(10, 6))  # Optional: Set the figure size
# fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)

plt.xlabel('date')
plt.grid(True)



# group data by academic semester
sem_groupby = df.groupby('semester')[["timestamp", "mass", "normalized mass"]]

p_year = 14
color = "blue"

# plot for each academic year on same axes
for sem, _df in sem_groupby:
    # if sem in ["14/15", "15/16", "16/17", "17/18", "23/24", "22/23"]:    #"17/18",, "19/20", "18/19", "20/21"]
    #     pass
    # else:
    #     # plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["mass"].cumsum(), label=f'{ac_year}')
    #     plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["mass"].cumsum(), label=f'{sem[:2]}')
    year = sem[-2:]

    # # cycle color
    # if year != p_year:
    #     color = next(ax1._get_lines.prop_cycler)['color']

    # p_year = year

    if year in ["14"]:    #"17/18",, "19/20", "18/19", "20/21"]
        pass
    else:
        plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["normalized mass"].cumsum(), label=f'{sem}')

# Set y-axis label for left subplot only
plt.title('Cumulative print mass (g)')
# plt.set_title("Fall")
# plt.set_title("Spring")
# plt.title("Cumulative Print mass vs. date by academic year and semester")
# Add title to subplot
# plt.suptitle(' Cumulative Print mass vs. date by academic year and semester ', fontsize=20)

# Display the plot
plt.legend(title="Academic Year")
# plt.legend(title="Academic Year")
plt.show()

df.head()
```

### Class/Reason Data Bar Charts

```{python}
# Set up plot
plt.figure(figsize=(10, 6))  # Optional: Set the figure size
plt.title("Filament Used Per Semester")         # Per reason
plt.xlabel('date')
plt.ylabel("Cumulative print mass (g)")
plt.grid(True)



# group data by academic year
sem_groupby = df.groupby('academic year')[["timestamp", "mass"]]

# plot for each academic year on same axes
for sem, _df in sem_groupby:
    if sem in ["14/15", "15/16", "16/17", "17/18", "23/24"]:    #"17/18",, "19/20", "18/19", "20/21", "22/23"
        pass
    else:
        print(f"year is {sem}")
        plt.plot(_df["timestamp"].apply(lambda x: get_ac_year_day(x)), _df["mass"].cumsum(), label=f'{sem}')
    # print(_df.head())

# Display the plot
plt.legend(title="Academic Year")
plt.show()
```

## Class Consumption By Semester Bar Graph

### Print Reason

```{python}
df.head()
```

### Deal with class names

```{python}
def correct_series(series, map:dict):
    """
    Iterate through each correct value in the map dictionary,
    performing a regex string replacement on the series that
    overwrites any matching value with the coorect value given
    by the map

    Args:
        series (pandas series): series to be corrected
        map (dict): dictionary that maps correction keys to 
                    a regex expression targeting incorrect
                    values (<correct value> : <regex query for misnomers>)
    
    Return:
        (pandas series): corrected pandas series
    """
    for correction_key in map:
        series = series.str.replace(map[correction_key], correction_key, regex=True, case=False)
    
    return series

# dictionary for defining name correction map
class_names_correction_map = {
    "DesNat" : "Desnat|desnT|DesNat|dednat|Des Nat|ddesnat|desnat|desNat|Design Nature",
    "Pass. Pursuit" : "passion.*",
    "PIE" : "pie.*",
    "DFM" : "dfm|.*manufact.*",
    "Scope" : ".*scope.*",
    "IS" : ".*indep.*|is.*",
    "Ren. Energy" : ".*renewable.*",
    "EEC" : ".*eec.*",
    "Mech Proto" : ".*proto.*|Mech Proto",
    "QEA" : ".*qea.*",
    "Research" : ".*research.*|.*lair.*",
    "P&M" : ".*market.*|p&.*|p[[:space:]]&.*|p &m",
    "SustDes" : ".*sust.*",
    "RoboSys" : ".*robos.*|.*Robotic System*.",
    "DBF" : ".*dbf.*|design[[:space:]]bu.*",
    "Formula" : "formula",
    "Large 3D Printer" : ".*rint*.",
    "Project Team or Club" : "DBF|Formula|Rocketry|Baja|pint"
}


# correct class names
df["class names corrected"] = correct_series(df["class"], class_names_correction_map)
```

### Create Bar Graph Plot

```{python}
# # find top 5 most frequent classes
# print(df['class names corrected'].value_counts()[:5].index.tolist())

# for testing purposes (before we dedupe the class names) I will test with this list of the top 5 class names
classes_top5 = ['Mech Proto', 'POE', 'DesNat', 'PIE', 'Project Team or Club']

# downselect df to top 5 classes only
df_top5 = df[df["class names corrected"].isin(classes_top5)]
df_top5.head()

# group by class name and semester
double_groupby = df_top5.groupby(["class names corrected", "semester"])["mass"].sum()

# convert that double groupby object into an iterable nested dict structure
semester_totals_by_class = {}
for key in double_groupby.keys():
    if key[0] not in semester_totals_by_class:
        semester_totals_by_class[key[0]] = {key[1]: double_groupby[key]}
    else:
        semester_totals_by_class[key[0]].update({key[1]: double_groupby[key]})

# test
for class_name, mass_by_sem in semester_totals_by_class.items():
    print(f"-------------{class_name}-------------")
    for sem, total_mass in mass_by_sem.items():
        print(f"{sem}: {total_mass}g")
```

### Testing out how to make the bar graph

#### Per class bar plot

```{python}
# creating the dataset
data = semester_totals_by_class["PIE"]

semesters = list(data.keys())
total_masses = list(data.values())

fig = plt.figure(figsize = (10, 5))

# creating the bar plot
plt.bar(semesters, total_masses,
		width = 0.4)

plt.xlabel("Semester")
plt.ylabel("Total mass printed")
plt.title("PIE")
plt.show()
```

```{python}
classes = ("PIE", "ADE", "Desnat")
class_masses = {
    'Fall 21': (18.35, 18.43, 14.98),
    'Spring 22': (38.79, 48.83, 47.50),
    'Fall 22': (18.35, 18.43, 14.98),
    'Spring 23': (38.79, 48.83, 47.50),
}

num_classes = 

x = np.arange(len(classes))  # the label locations
width = 0.25  # the width of the bars
multiplier = 0

fig, ax = plt.subplots(layout='constrained')

for semester, mass in class_masses.items():
    offset = width * multiplier
    rects = ax.bar(x + offset, mass, width, label=semester)
    ax.bar_label(rects, padding=3)
    multiplier += 1

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Length (mm)')
ax.set_title('Penguin attributes by species')
ax.set_xticks(x + width, classes)
ax.legend(loc='upper left', ncols=3)
ax.set_ylim(0, 250)

plt.show()
```

#### All Classes Bar Plot

```{python}
# create data 
df = pd.DataFrame([['A', 10, 20, 10, 30], ['B', 20, 25, 15, 25], ['C', 12, 15, 19, 6], 
                   ['D', 10, 29, 13, 19]], 
                  columns=['Team', 'Round 1', 'Round 2', 'Round 3', 'Round 4']) 
# view data 
print(df) 
  
# plot grouped bar chart 
df.plot(x='Team', 
        kind='bar', 
        stacked=False, 
        title='Grouped Bar Graph with dataframe') 
```

```{python}
df = pd.DataFrame(double_groupby)

# view data 
print(df)

# plot grouped bar chart 
df.plot(x='class names corrected', 
        kind='bar', 
        stacked=False, 
        title='Grouped Bar Graph with dataframe') 
```

```{python}
import seaborn as sns
sns.countplot(data=df,x='category',hue='sex')

# or,
sns.catplot(data=df,kind='count',x='category',hue='sex')
```

## Deal with student names?

```{python}
# do later, holy shit
```


